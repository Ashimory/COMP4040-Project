{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, RobertaTokenizerFast, RobertaForSequenceClassification, pipeline\n",
    "import json\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttd_data_folder = \"../BioT5/data/\"\n",
    "text2mol_train_set, mol2text_train_set = dict(), dict()\n",
    "with open(ttd_data_folder + \"tasks/task201_COVID_drug_generation_train.json\") as fm2t,  open(ttd_data_folder + \"tasks/task202_COVID_drug_generation_train.json\") as ft2m:\n",
    "    text2mol_train_set = json.load(ft2m)\n",
    "    mol2text_train_set = json.load(fm2t)\n",
    "train_size = len(text2mol_train_set[\"Instances\"])\n",
    "train_mols = [row[\"input\"][5:-5] for row in mol2text_train_set[\"Instances\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "generation_tokenizer = T5Tokenizer.from_pretrained(\"QizhiPei/biot5-base-text2mol\", model_max_length=512)\n",
    "generation_model = T5ForConditionalGeneration.from_pretrained('../models/biot5-base-text2mol-finetuned', use_safetensors=True)\n",
    "\n",
    "# pred_tokenizer = RobertaTokenizerFast.from_pretrained(\"../model/chemberta\")\n",
    "# pred_model = RobertaForSequenceClassification.from_pretrained(\"../model/chemberta\")\n",
    "# classifier = pipeline(\"text-classification\", model = \"../models/chemberta\")\n",
    "\n",
    "task_definition = 'Definition: You are given a molecule description in English. Your job is to generate the molecule SELFIES that fits the description.\\n\\n'\n",
    "text_input = 'The molecule is a COVID-19 drug candidate.'\n",
    "task_input = f'Now complete the following example -\\nInput: {text_input}\\nOutput: '\n",
    "\n",
    "model_input = task_definition + task_input\n",
    "input_ids = generation_tokenizer(model_input, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generation_config = generation_model.generation_config\n",
    "generation_config.max_length = 512\n",
    "generation_config.num_beams = 1\n",
    "generation_size = train_size * 4 #x5 original training set in total\n",
    "\n",
    "mol_selfies = []\n",
    "mol_smiles = []\n",
    "dupes = 0\n",
    "\n",
    "for i in range(generation_size):  \n",
    "    outputs = generation_model.generate(input_ids, generation_config=generation_config)\n",
    "    output_selfies = generation_tokenizer.decode(outputs[0], skip_special_tokens=True).replace(' ', '')\n",
    "    # print(output_selfies)\n",
    "    mol_selfies.append(output_selfies)\n",
    "    import selfies as sf\n",
    "    output_smiles = sf.decoder(output_selfies)\n",
    "    mol_smiles.append(output_smiles)\n",
    "    # print(output_smiles)\n",
    "    if mol_selfies in train_mols:\n",
    "        dupes += 1\n",
    "\n",
    "# mol_activity = [1 if result[\"label\"] == 'LABEL_1' else 0 for result in classifier(mol_smiles)]\n",
    "# predicted_activity_rate = np.average(mol_activity)\n",
    "# print(predicted_activity_rate)\n",
    "# print(dupes/generation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "generation_tokenizer = T5Tokenizer.from_pretrained(\"QizhiPei/biot5-base-mol2text\", model_max_length=512)\n",
    "generation_model = T5ForConditionalGeneration.from_pretrained('../models/biot5-base-mol2text-finetuned', use_safetensors=True)\n",
    "\n",
    "generation_config = generation_model.generation_config\n",
    "generation_config.max_length = 512\n",
    "generation_config.num_beams = 1\n",
    "\n",
    "task_definition = 'Definition: You are given a molecule SELFIES. Your job is to generate the molecule description in English that fits the molecule SELFIES.\\n\\n'\n",
    "\n",
    "mol_descs = []\n",
    "\n",
    "for mol in mol_selfies:\n",
    "    task_input = f'Now complete the following example -\\nInput: <bom>{mol}<eom>\\nOutput: '\n",
    "    model_input = task_definition + task_input\n",
    "    input_ids = generation_tokenizer(model_input, return_tensors=\"pt\").input_ids\n",
    "    outputs = generation_model.generate(input_ids, generation_config=generation_config)\n",
    "    desc = generation_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    mol_descs.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol2text_task_id = 201 #arbitrary id number, biot5's task ids go up to 180. \n",
    "text2mol_task_id = 202\n",
    "\n",
    "os.makedirs(\"../BioT5/data/splits/covid/mol2text_augmented/\", exist_ok=True)\n",
    "os.makedirs(\"../BioT5/data/splits/covid/text2mol_augmented/\", exist_ok=True)\n",
    "\n",
    "for i in range(len(mol_descs)):\n",
    "    mol2text_train_set[\"Instances\"].append({\n",
    "    \"id\": f\"task{mol2text_task_id}-{uuid.uuid4().hex}\",\n",
    "    \"input\": f\"<bom>{mol_selfies[i]}<eom>\",\n",
    "    \"output\": [mol_descs[i]]\n",
    "    })\n",
    "    text2mol_train_set[\"Instances\"].append({\n",
    "        \"id\": f\"task{text2mol_task_id}-{uuid.uuid4().hex}\",\n",
    "        \"input\": mol_descs[i],\n",
    "        \"output\": [f\"<bom>{mol_selfies[i]}<eom>\"]\n",
    "    })\n",
    "with open(f'../BioT5/data/tasks/task{mol2text_task_id}_COVID_drug_generation_train_augmented.json', \"w\") as out:\n",
    "    json.dump(mol2text_train_set, out, indent=4)\n",
    "with open(f'../BioT5/data/tasks/task{text2mol_task_id}_COVID_drug_generation_train_augmented.json', \"w\") as out:\n",
    "    json.dump(text2mol_train_set, out, indent=4)\n",
    "\n",
    "for dset in [\"train_augmented\", \"validation\", \"test\"]:\n",
    "    with open(f'../BioT5/data/splits/covid/mol2text_augmented/{dset}_tasks.txt', \"w\") as out:\n",
    "        out.write(f'task{mol2text_task_id}_COVID_drug_generation_{dset}')\n",
    "    with open(f'../BioT5/data/splits/covid/text2mol_augmented/{dset}_tasks.txt', \"w\") as out:\n",
    "        out.write(f'task{text2mol_task_id}_COVID_drug_generation_{dset}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp4040",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
